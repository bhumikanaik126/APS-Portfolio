
## **Urn Model + Probability — Spotting Anomalous Reviewer Behavior**

### 🎯 The Challenge

Fake reviewers and bots often behave in ways that **don’t match natural human review patterns**:

* One user leaving 20 reviews in 5 minutes
* Burst of 5-star reviews for a business in an hour
* Consistently extreme ratings (1 or 5 stars)

We need a way to **mathematically assess how likely** such behavior is.

---

### 🚀 The Solution: Urn Model + Probabilistic Deviation Detection

The **Urn Model** simulates expected probabilities of outcomes (like drawing colored balls from an urn). When reviewer behavior **deviates significantly** from expected norms, it signals fraud.

---

### 🧠 Why Urn Model?

* Models **expected distributions** (e.g., normal rate of reviews/day/user)
* Detects **low-probability events** (e.g., sudden spike in reviews)
* Gives **statistical thresholds** for anomaly detection

Used for:

* Spotting **review spamming bots**
* Identifying **manipulated business ratings**
* Estimating **trustworthiness** of a user

---

### 🌐 Conceptual Flow Example

Say the average user posts 1 review/day. You model this as an urn:

* Each ball = chance of posting 1 review
* Drawing 20 review-posting events in an hour = **very unlikely**

If probability(P) < 0.01, flag for review.

---

### 💡 Algorithmic Insight

**Goal**: Estimate probability of observed review burst given expected rate.

**Core Steps**:

1. For each user/business:

   * Compute expected distribution (Poisson/Binomial)
2. Track observed count in a time window
3. Compute P(observed count | expected)
4. If P is low, flag as suspicious

---
### 🛠 C++ Implementation
[View code here](https://github.com/bhumikanaik126/APS-Portfolio/blob/main/codes/b10.cpp)<br><br>

---

### ⏱️ Time and Space Complexity

| Operation                      | Complexity |
| ------------------------------ | ---------- |
| Probability Calculation        | O(1)       |
| Data Storage for Users/Reviews | O(N)       |

---

### 🧪 Google Use Case

* **Google Maps**: Flag businesses getting a **suspicious spike** in reviews in a short window
* **Google Play**: Catch apps that suddenly receive **hundreds of glowing reviews** from new accounts
* Combined with geolocation to find fake **"local" reviews**

---

### ⚙️ Backend Enhancements

* Maintain user and business review rates using **moving averages**
* Adjust thresholds based on **reviewer history**
* Auto-cluster suspicious activity by **IP or time proximity**

---

### 🖼️ Visualization

* Line graph: expected vs observed review rate
* Probability heat map of review anomalies

---

### 💡 Key Takeaways

* Urn models add **statistical reasoning** to review spam detection
* Google can flag users/businesses for **manual review or auto-muting**
* Forms a **first line of defense** in large-scale review integrity

---
